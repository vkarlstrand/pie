{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44767758",
   "metadata": {},
   "source": [
    "# Adversarial Attack and Detection in Medical Images using Deap Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaccf21",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import common libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8d448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a319fa84",
   "metadata": {},
   "source": [
    "## Partition data\n",
    "Partition the data defined in a .csv file, where each row holds the file name of the images and their corresponding label, into three different .csv files; for training, validation and testing. You can specify the ratios of training, validation and test data sets as well as the output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff066543",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7555109",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTITION = False                             # Set to false once data has been partitioned into .csv files\n",
    "\n",
    "PARTITION_INPUT_FILE = 'data/data_labels.csv' # File with original images and labels\n",
    "PARTITION_RATIOS = [0.70, 0.15, 0.15]         # Ratios of training, validation, and test data\n",
    "PARTITION_UNIFORM = False                     # If to partition data and labels uniformly\n",
    "PARTITION_OUT_PATH = 'data/2021-11-11/'       # Out path for .csv files for training, validation, and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea935d",
   "metadata": {},
   "source": [
    "#### Parition data into training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f423af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import partition_data\n",
    "\n",
    "if PARTITION:\n",
    "    partition_data(input_file=PARTITION_INPUT_FILE,\n",
    "                   ratios=PARTITION_RATIOS,\n",
    "                   out_path=PARTITION_OUT_PATH,\n",
    "                   uniform=PARTITION_UNIFORM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981b1cf8",
   "metadata": {},
   "source": [
    "## Import and transform data\n",
    "Import the data as training, validation and test data and augment the images if wanted to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608f2c2",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dad90448",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128                           # Image size to resize images to\n",
    "BATCH_SIZE = 16                            # Batch size to use\n",
    "NUM_WORKERS = 4                            # Number of workers\n",
    "IMAGE_ROOT = './data/data_images/'         # Path to images\n",
    "PARTITION_PATH_ROOT = './data/2021-11-11/' # Path to .csv files with training, validation and test data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ac2bc",
   "metadata": {},
   "source": [
    "#### Import and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b87041be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'dataloader_to_tensors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2f15f5ab6133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0malbum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malbumentations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToTensorV2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoadDatasetFromCSV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_to_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'dataloader_to_tensors'"
     ]
    }
   ],
   "source": [
    "import albumentations as album\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from data import LoadDatasetFromCSV\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Resize images and rescale values\n",
    "album_compose = album.Compose([\n",
    "    album.Resize(IMAGE_SIZE, IMAGE_SIZE),                                          # Resize to IMAGE_SIZE x IMAGE_SIZE\n",
    "    album.Normalize(mean=[0.0,0.0,0.0], std=[1.0,1.0,1.0], max_pixel_value=255.0), # Rescale values from [0,255] to [0,1]\n",
    "    album.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5], max_pixel_value=1.0),   # Rescale values from [0,1] to [-1,1]\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# Load training and validation data set\n",
    "dataset_train = LoadDatasetFromCSV(image_root=IMAGE_ROOT,\n",
    "                                   csv_path=PARTITION_PATH_ROOT+'data_labels_train.csv',\n",
    "                                   transforms=album_compose)\n",
    "dataset_valid = LoadDatasetFromCSV(image_root=IMAGE_ROOT,\n",
    "                                   csv_path=PARTITION_PATH_ROOT+'data_labels_validation.csv',\n",
    "                                   transforms=album_compose)\n",
    "\n",
    "# Load data into loaders\n",
    "dataloader_train = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "dataloader_valid = DataLoader(dataset=dataset_valid, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4075e169",
   "metadata": {},
   "source": [
    "#### Plot some examples from training and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import plot_dataloader\n",
    "\n",
    "rows, cols, width = 3, 4, 4\n",
    "\n",
    "# Plot training data\n",
    "fig, axs = plot_dataloader(dataloader_train, rows=rows, cols=cols, width=width)\n",
    "fig.suptitle('Some examples from training data', fontsize=24, y=0.95, weight='bold')\n",
    "plt.show()\n",
    "\n",
    "# Plot validation data\n",
    "fig, axs = plot_dataloader(dataloader_valid, rows=rows, cols=cols, width=width)\n",
    "fig.suptitle('Some examples from validation data', fontsize=24, y=0.95, weight='bold')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
